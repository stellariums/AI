{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "# 导入必要的Python库\n",
    "# tqdm: 用于显示进度条，让长时间运行的代码看起来更友好\n",
    "# matplotlib.pyplot: 用于数据可视化，创建各种图表\n",
    "# seaborn: 基于matplotlib的高级可视化库，提供更美观的图表\n",
    "# lightgbm: 微软开发的梯度提升框架，用于机器学习建模\n",
    "# pandas: 数据处理和分析的核心库，用于处理表格数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "# 导入scikit-learn库中的关键模块\n",
    "# StandardScaler: 标准化处理器，用于将特征缩放到均值为0，方差为1的标准正态分布\n",
    "# LabelEncoder: 标签编码器，将类别特征转换为数值标签\n",
    "# KFold: K折交叉验证工具，用于模型验证和防止过拟合\n",
    "# roc_auc_score: ROC曲线下面积指标，用于评估二分类模型的性能\n",
    "# log_loss: 对数损失函数，用于评估概率预测的准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"/kaggle/input/deepshare-playground-series2/train_data.csv\")\n",
    "test_df=pd.read_csv(\"/kaggle/input/deepshare-playground-series2/test_data.csv\")\n",
    "# 从Kaggle数据集路径读取训练和测试数据\n",
    "# train_df: 训练数据集，包含特征和标签，用于训练机器学习模型\n",
    "# test_df: 测试数据集，通常只包含特征，用于模型预测\n",
    "# 注意：需要先在Kaggle上下载数据集并放在指定路径下才能运行\n",
    "# 数据集路径：/kaggle/input/deepshare-playground-series2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([train_df,test_df],axis=0).reset_index(drop=True)\n",
    "# 合并训练集和测试集数据\n",
    "# pd.concat(): pandas的合并函数，将多个数据框按行或列合并\n",
    "# axis=0: 表示按行合并（垂直堆叠）\n",
    "# reset_index(drop=True): 重新设置索引，删除原来的索引\n",
    "# 这样做的目的通常是为了统一处理特征工程，保持一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=[f'user_fea{i}' for i in range(6,9)]\n",
    "cate_cols=['user_id','item_id']+[f'user_fea{i}' for i in range(1,6)]+['item_fea1']+['user_fea9']\n",
    "# 定义数值特征和类别特征列名\n",
    "# num_cols: 数值特征列，包含user_fea6, user_fea7, user_fea8\n",
    "# 这些是连续的数值型特征，通常需要进行标准化处理\n",
    "# cate_cols: 类别特征列，包含用户ID、物品ID和其他分类特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#连续特征\n",
    "for col in tqdm(num_cols):\n",
    "    plt.figure(dpi=150)\n",
    "    sns.displot(df[col])\n",
    "# 可视化数值特征的分布情况\n",
    "# 这有助于了解数据的分布特征，发现异常值或偏态分布\n",
    "# tqdm(num_cols): 为循环添加进度条，显示处理进度\n",
    "# plt.figure(dpi=150): 设置图表分辨率为150dpi，提高图像清晰度\n",
    "# sns.displot(): seaborn的分布图函数，显示数据的分布情况\n",
    "# 这个循环会为每个数值特征生成一个分布图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正确的标准化流程：只在训练集上拟合，然后转换训练集和测试集\n",
    "scaler=StandardScaler()\n",
    "# 第一步：在训练集上拟合scaler（计算均值和标准差）\n",
    "scaler.fit(train_df[num_cols])\n",
    "# 第二步：用同一个scaler转换训练集\n",
    "train_df[num_cols]=scaler.transform(train_df[num_cols])\n",
    "# 第三步：用同一个scaler转换测试集\n",
    "test_df[num_cols]=scaler.transform(test_df[num_cols])\n",
    "# 重要原则：\n",
    "# 1. 标准化参数（均值、标准差）只能从训练集学习\n",
    "# 2. 测试集必须使用训练集学习到的参数进行转换\n",
    "# 3. 这样可以避免数据泄露，确保模型评估的公正性\n",
    "# 4. 绝不能在合并数据上fit，否则会造成信息泄露"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正确的类别特征编码流程：只在训练集上拟合，然后转换训练集和测试集\n",
    "for col in tqdm(cate_cols):\n",
    "    le=LabelEncoder()\n",
    "    # 第一步：在训练集上拟合LabelEncoder\n",
    "    le.fit(train_df[col])\n",
    "    # 第二步：用同一个LabelEncoder转换训练集\n",
    "    train_df[col]=le.transform(train_df[col])\n",
    "    # 第三步：用同一个LabelEncoder转换测试集\n",
    "    test_df[col]=le.transform(test_df[col])\n",
    "# 对类别特征进行标签编码\n",
    "# LabelEncoder: 将类别特征转换为数值标签（0, 1, 2, ...）\n",
    "# 例如：['男', '女', '男'] -> [0, 1, 0]\n",
    "# 重要原则：\n",
    "# 1. 编码映射关系只能从训练集学习\n",
    "# 2. 测试集必须使用训练集学习到的映射关系\n",
    "# 3. 这样可以避免数据泄露，确保模型评估的公正性\n",
    "# 4. 如果测试集有训练集中未出现的类别，需要特殊处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=df[df['label'].notna()].reset_index(drop=True)\n",
    "test_df=df[df['label'].isna()].reset_index(drop=True)\n",
    "# 根据标签列重新分割训练集和测试集\n",
    "# df['label'].notna(): 选择标签不为空的行（训练数据）\n",
    "# df['label'].isna(): 选择标签为空的行（测试数据）\n",
    "# reset_index(drop=True): 重新设置索引，删除原来的索引\n",
    "# 这种分割方式假设原始数据中训练集有标签，测试集没有标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape,test_df.shape\n",
    "# 查看训练集和测试集的维度（形状）\n",
    "# .shape 返回一个元组，表示数据的行数和列数\n",
    "# 例如：(1000, 20) 表示1000行20列的数据\n",
    "# 这有助于确认数据分割是否正确，以及数据规模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feature=['ID','label','day','item_desc','lng','lat','ts','user_tag']\n",
    "features=[x for x in train_df.columns if x not in drop_feature]\n",
    "print(len(features),features)\n",
    "# 选择用于建模的特征\n",
    "# drop_feature: 需要删除的列，这些列通常不是模型输入特征\n",
    "# ID: 样本ID，没有预测价值\n",
    "# label: 标签列，这是我们要预测的目标\n",
    "# day, item_desc, lng, lat, ts, user_tag: 可能需要特殊处理或暂时不用的特征\n",
    "# features: 最终用于训练模型的特征列表\n",
    "# len(features): 特征的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型调用\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val=train_test_split(train_df[features],train_df['label'],test_size=0.2,random_state=2025)\n",
    "# 划分训练集和验证集\n",
    "# train_test_split: 将训练数据进一步分为训练集和验证集\n",
    "# train_df[features]: 特征数据\n",
    "# train_df['label']: 标签数据\n",
    "# test_size=0.2: 验证集占20%，训练集占80%\n",
    "# random_state=2025: 随机种子，确保每次划分结果一致\n",
    "# 返回四个数组：训练特征、验证特征、训练标签、验证标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=lgb.LGBMClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "y_val_pred=model.predict_proba(x_val)[:,1]\n",
    "\n",
    "print(f'AUC:{roc_auc_score(y_val,y_val_pred)}')\n",
    "print(f'logloss:{log_loss(y_val,y_val_pred)}')\n",
    "\n",
    "y_pred=model.predict_proba(test_df[features])[:,1]\n",
    "# 训练LightGBM模型并进行预测\n",
    "# lgb.LGBMClassifier(): 创建LightGBM分类器\n",
    "# model.fit(): 在训练数据上拟合模型\n",
    "# predict_proba(): 预测概率，返回每个类别的概率\n",
    "# [:,1]: 取第二列，即正类（类别1）的概率\n",
    "# roc_auc_score: 计算AUC指标，评估模型性能\n",
    "# log_loss: 计算对数损失，另一个评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "sklearn_sub_df=pd.DataFrame({\n",
    "    'ID':test_df['ID'],\n",
    "    'label':y_pred\n",
    "})\n",
    "sklearn_sub_df.to_csv('/kaggle/working/sklearn_baseline.csv',index=False)\n",
    "# 创建提交文件\n",
    "# pd.DataFrame(): 创建数据框，包含ID和预测结果\n",
    "# 'ID': 测试样本的唯一标识符\n",
    "# 'label': 模型预测的概率值\n",
    "# to_csv(): 将结果保存为CSV文件\n",
    "# '/kaggle/working/sklearn_baseline.csv': 保存路径，符合Kaggle格式\n",
    "# index=False: 不保存行索引\n",
    "# 这个文件可以直接提交到Kaggle竞赛平台"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
